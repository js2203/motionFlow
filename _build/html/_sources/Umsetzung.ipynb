{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umsetzung "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Motion-Flow Schätzung und Netzwerk-Design**<br><br>\n",
    "Das Ziel dieses FCN-Netzwerks besteht darin, eine **End-to-End-Mapping** von einem unscharfen Bild auf dessen entsprechende Motion Flow Map zu erreichen. Gegeben sei ein beliebiges RGB-Bild mit der willkürlichen Größe $P\\times Q$. Das FCN wird dazu verwendet eine Motion Flow-Map zu schätzen $M=(U,V)$ mit der gleichen Größe wie das Eingabebild, wobei $U(i,j)\\in D_u^+$ and $V(i,j)\\in D_v$, $\\forall i,j$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text in Stichpunkten:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RGB-Bild mit der willkürlichen Größe $P\\times Q$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Motion-Flow-Map $M=(U,V)$ mit der gleichen Größe wie das Eingabebild wird geschätzt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$U(i,j)\\in D_u^+$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$V(i,j)\\in D_v, \\forall i,j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abbildung 4**![FCN_MotionFlow.PNG](./FCN_MotionFlow.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Bequemlichkeit, lassen wir  $D=|D_u^+| + |D_v|$ die Gesamtzahl der Labels bezeichnen\n",
    "sowohl für $U$ als auch für $V$. Die Netzwerkstruktur ist wie in Abbildung 4 gezeigt, verwendet werden 7 Faltungs-(conv) Layer und 4 Max-Pooling (Pool) Layer sowie 3 uconv-Layer zum Upsampling der Prediction-Map. Uconv bezeichnet  die fraktionierte Faltung, auch bekannt als Deconvolution. Es wird ein kleiner Stride(Schritt) von 1 Pixel für alle Faltungsschichten verwendet. Die uconv-Layer werden mit bilinearer Interpolation initialisiert und werden zum Upsampling der Aktivierungsfunktionen verwendet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$D=|D_u^+| + |D_v|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **7 Faltungs-(conv) Layer**\n",
    "- **4 Max-Pooling (Pool) Layer**\n",
    "- **3 uconv-Layer** zum Upsampling der Prediction-Map\n",
    "- **Skip-Verbindungen**\n",
    "- **$P \\times Q \\times D$-Tensor**, Feature-Map des letzten uconv-Layers (conv7 + uconv2)\n",
    "- **Stride(Schritt) von 1 Pixel** für alle Faltungsschichten\n",
    "- **uconv-Layer**(Deconvolutional-Layer) mit bilinearer Interpolation initialisiert, Upsampling der Aktivierungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es werden auch Skip-Verbindungen hinzugefügt, die die Informationen aus verschiedenen Schichten kombinieren, wie in Abbildung 4 gezeigt.\n",
    "Die Feature-Map des letzten uconv-Layers (conv7 + uconv2)\n",
    "ist ein $P \\times Q \\times D$-Tensor mit den oberen $|D_u^+|$-Slices von Feature-Maps ($P \\times Q \\times |D_u^+|$) entsprechend der Schätzung von $U$ und den verbleibenden $|D_v|$-Slices von Feature-Maps\n",
    "($P \\times Q \\times |D_v|$) entsprechend der Schätzung von $V$. Zwei\n",
    "separate Soft-Max-Layer werden jeweils auf diese beiden Teile angewendet, um die Posterior-Wahrscheinlichkeitsschätzung von beiden Kanälen zu erhalten. Sei $F_{u,i,j}(Y)$ die Wahrscheinlichkeit, dass\n",
    "der Pixel bei $(i, j)$ eine Bewegung $u$ entlang der horizontalen\n",
    "Richtung gemacht hat und $F_{v,i,j}(Y)$ repräsentiert die Wahrscheinlichkeit, dass der\n",
    "Pixel bei $(i, j)$ eine Bewegung $v$ entlang der vertikalen Richtung gemacht hat. Es wird dann die Summe des Kreuzentropieverlustes von beiden Kanälen als die Finale Loss-Function verwendet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Posterior-Wahrscheinlichkeitsschätzung von beiden Kanälen**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$F_{u,i,j}(Y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$F_{v,i,j}(Y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mit den oberen $|D_u^+|$-Slices von Feature-Maps ($P \\times Q \\times |D_u^+|$) entsprechend der Schätzung von $U$ und den verbleibenden $|D_v|$-Slices von Feature-Maps\n",
    "($P \\times Q \\times |D_v|$) entsprechend der Schätzung von $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior-Wahrscheinlichkeitsschätzung von beiden Kanälen zu erhalten. Sei $F_{u,i,j}(Y)$ die Wahrscheinlichkeit, dass\n",
    "der Pixel bei $(i, j)$ eine Bewegung $u$ entlang der horizontalen\n",
    "Richtung gemacht hat und $F_{v,i,j}(Y)$ repräsentiert die Wahrscheinlichkeit, dass der\n",
    "Pixel bei $(i, j)$ eine Bewegung $v$ entlang der vertikalen Richtung gemacht hat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wird dann die **Summe des Kreuzentropieverlustes von beiden Kanälen** als die **Finale Loss-Function** verwendet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FCN_MotionFlow.PNG](./loss.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$1$ ist eine Indikator Funktion\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
